from torch.utils import data
from torchvision import transforms
import os
import os.path
from PIL import Image
import random
import numpy as np
from utils import cv_utils
import pickle
import cv2

def get_loader(config, dataset_name='EM', mode='train', num_workers=1):
    """Build and return a data loader."""

    dataset = AusDataset(config, mode, dataset_name)
    data_loader = data.DataLoader(dataset=dataset,
                                  batch_size=50,
                                  # shuffle=False,
                                  shuffle=(mode == 'train'),
                                  drop_last=True,
                                  num_workers=num_workers)
    # else:
    #     raise ValueError("Dataset [%s] not recognized." % dataset_name)


    return data_loader


class DatasetBase(data.Dataset):
    def __init__(self):
        super(DatasetBase, self).__init__()
        self._name = 'BaseDataset'
        self.root = None

        # self.create_transform()

        self.IMG_EXTENSIONS = [
            '.jpg', '.JPG', '.jpeg', '.JPEG',
            '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',
        ]

    @property
    def name(self):
        return self._name

    @property
    def path(self):
        return self.root



    def is_image_file(self, filename):
        return any(filename.endswith(extension) for extension in self.IMG_EXTENSIONS)

    def is_csv_file(self, filename):
        return filename.endswith('.csv')

    def get_all_files_in_subfolders(self, dir, is_file):
        images = []
        assert os.path.isdir(dir), '%s is not a valid directory' % dir

        for root, _, fnames in sorted(os.walk(dir)):
            for fname in fnames:
                if is_file(fname):
                    path = os.path.join(root, fname)
                    images.append(path)
        return images


class AusDataset(DatasetBase):
    def __init__(self, config, mode, dataset_name):
        super(AusDataset, self).__init__()
        self.dataset_name = dataset_name
        self.config=config
        if dataset_name=='CR':
            self.imgs_dir =config.buffer_dir
            self.attr_path=os.path.join(config.buffer_dir,config.generated_aus_file)
            self.mode = mode
            self.root=self.config.buffer_dir
        else:
            print("Wrong datasets!")

        self.create_transform()
        self.read_dataset()

    def __getitem__(self, index):
        assert (index < self.dataset_size)

        # start_time = time.time()

        # if sample randomly: overwrite index
        if not self.config.serial_batches:
            index = random.randint(0, self.dataset_size - 1)

        # get sample data
        sample_id = self.ids[index]

        real_img = self.get_img_by_id(sample_id)     ##have modification here
        label = self.get_cond_by_id(sample_id)                  ##have modification here

        if real_img is None:
            print('error reading image %s, skipping sample' % sample_id)
        if label is None:
            print('error reading labels %s, skipping sample' % sample_id)

        # transform data
        img = self.transform(Image.fromarray(real_img))

        return img,label

    def __len__(self):
        return self.dataset_size

    def read_dataset(self):
        # read aus
        conds_filepath = self.attr_path
        self.labels = self.read_conds(conds_filepath)          ## conditions are generated by openface.

        self.ids=list(self.labels.keys())       ##only for test.

        # self.ids = list(set(self.ids).intersection(set(self.labels.keys())))  ## comment this time temporarily

        # dataset size
        self.dataset_size = len(self.ids)


        print('Finished preprocessing the {} dataset...'.format(self.name))

    def create_transform(self):
        if self.mode=='train':
            transform_list = [transforms.RandomHorizontalFlip(),
                              transforms.Resize(128),
                              transforms.ToTensor(),
                              transforms.Normalize(mean=[0.5, 0.5, 0.5],
                                                   std=[0.5, 0.5, 0.5]),
                              ]
        else:
            transform_list = [transforms.Resize(128),
                              transforms.ToTensor(),
                              transforms.Normalize(mean=[0.5, 0.5, 0.5],
                                                   std=[0.5, 0.5, 0.5]),
                              ]
        self.transform = transforms.Compose(transform_list)

    def read_ids(self, file_path):
        with open(file_path, 'rb') as f:
            ids = pickle.load(f, encoding='utf-8')
            f.close()
        return ids

    def read_conds(self, file_path):
        with open(file_path, 'rb') as f:
            return pickle.load(f, encoding='latin1')

    def get_cond_by_id(self, id):
        if id in self.labels:
            return self.labels[id]
        else:
            return None

    def get_img_by_id(self, id):
        img = None
        for suffix in self.IMG_EXTENSIONS:
            filepath =self.imgs_dir+'/'+ id+suffix
            # filepath = self.imgs_dir + '/1-exp-cls/' + id + suffix
            if os.path.exists(filepath):
                img=cv_utils.read_cv2_img(filepath)
                break
        return img





